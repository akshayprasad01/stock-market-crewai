{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_share_price(ticker_symbol):\n",
    "    try:\n",
    "        # Fetch data for the given ticker symbol\n",
    "        stock = yf.Ticker(ticker_symbol)\n",
    "        stock_info = stock.history(period=\"1d\")\n",
    "        print(stock_info)\n",
    "\n",
    "        # Extract the latest closing price\n",
    "        if not stock_info.empty:\n",
    "            latest_price = stock_info['Close'].iloc[-1]\n",
    "            print(f\"Latest price for {ticker_symbol}: ₹{latest_price:.2f}\")\n",
    "        else:\n",
    "            print(f\"No data available for {ticker_symbol}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Open      High            Low  \\\n",
      "Date                                                                \n",
      "2024-12-23 00:00:00+05:30  128632.351562  129999.0  128083.296875   \n",
      "\n",
      "                                   Close  Volume  Dividends  Stock Splits  \n",
      "Date                                                                       \n",
      "2024-12-23 00:00:00+05:30  129797.046875      37        0.0           0.0  \n",
      "Latest price for MRF.BO: ₹129797.05\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "ticker_symbol = \"RELIANCE.NS\"  # Replace with your desired stock ticker\n",
    "ticker_symbol = \"MRF.BO\"\n",
    "get_share_price(ticker_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"\n",
    "  Hi      this is       Aksha Y \"\"\"\n",
    "\n",
    "b = dedent(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHi      this is       Aksha Y '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_ibm\n",
      "  Using cached langchain_ibm-0.3.5-py3-none-any.whl (24 kB)\n",
      "Collecting ibm-watsonx-ai<2.0.0,>=1.1.16\n",
      "  Using cached ibm_watsonx_ai-1.1.26-py3-none-any.whl (1.0 MB)\n",
      "Collecting langchain-core<0.4,>=0.3.0\n",
      "  Using cached langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
      "Requirement already satisfied: requests in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm) (2.32.3)\n",
      "Collecting httpx\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: urllib3 in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm) (2.2.3)\n",
      "Collecting pandas<2.2.0,>=0.24.2\n",
      "  Using cached pandas-2.1.4-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Requirement already satisfied: certifi in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm) (2024.12.14)\n",
      "Collecting lomond\n",
      "  Using cached lomond-0.3.3-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: packaging in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm) (24.2)\n",
      "Collecting ibm-cos-sdk<2.14.0,>=2.12.0\n",
      "  Using cached ibm-cos-sdk-2.13.6.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting importlib-metadata\n",
      "  Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting PyYAML>=5.3\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langsmith<0.3,>=0.1.125\n",
      "  Downloading langsmith-0.2.6-py3-none-any.whl (325 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.7/325.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3.0.0,>=2.5.2\n",
      "  Using cached pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3.0->langchain_ibm) (4.12.2)\n",
      "Collecting ibm-cos-sdk-core==2.13.6\n",
      "  Using cached ibm-cos-sdk-core-2.13.6.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ibm-cos-sdk-s3transfer==2.13.6\n",
      "  Using cached ibm-cos-sdk-s3transfer-2.13.6.tar.gz (139 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jmespath<=1.0.1,>=0.10.0\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from ibm-cos-sdk-core==2.13.6->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm) (2.9.0.post0)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.2-py3-none-any.whl (63 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Using cached orjson-3.10.12-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting anyio\n",
      "  Using cached anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: idna in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from httpx->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm) (3.10)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting numpy<2,>=1.23.2\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm) (2024.2)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Using cached pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from requests->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm) (3.4.0)\n",
      "Collecting zipp>=3.20\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/akshay/Desktop/MARC Agent/env/lib/python3.11/site-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain_ibm) (1.17.0)\n",
      "Collecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zipp, tenacity, tabulate, sniffio, requests, PyYAML, pydantic-core, orjson, numpy, lomond, jsonpointer, jmespath, h11, annotated-types, requests-toolbelt, pydantic, pandas, jsonpatch, importlib-metadata, ibm-cos-sdk-core, httpcore, anyio, ibm-cos-sdk-s3transfer, httpx, langsmith, ibm-cos-sdk, langchain-core, ibm-watsonx-ai, langchain_ibm\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.0\n",
      "    Uninstalling numpy-2.2.0:\n",
      "      Successfully uninstalled numpy-2.2.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "\u001b[33m  DEPRECATION: ibm-cos-sdk-core is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for ibm-cos-sdk-core ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33m  DEPRECATION: ibm-cos-sdk-s3transfer is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for ibm-cos-sdk-s3transfer ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33m  DEPRECATION: ibm-cos-sdk is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for ibm-cos-sdk ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.7.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 ibm-cos-sdk-2.13.6 ibm-cos-sdk-core-2.13.6 ibm-cos-sdk-s3transfer-2.13.6 ibm-watsonx-ai-1.1.26 importlib-metadata-8.5.0 jmespath-1.0.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.28 langchain_ibm-0.3.5 langsmith-0.2.6 lomond-0.3.3 numpy-1.26.4 orjson-3.10.12 pandas-2.1.4 pydantic-2.10.4 pydantic-core-2.27.2 requests-2.32.2 requests-toolbelt-1.0.0 sniffio-1.3.1 tabulate-0.9.0 tenacity-9.0.0 zipp-3.21.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_ibm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'ibm/granite-8b-code' is not supported for this environment. Supported models: ['codellama/codellama-34b-instruct-hf', 'google/flan-t5-xl', 'google/flan-t5-xxl', 'google/flan-ul2', 'ibm/granite-13b-chat-v2', 'ibm/granite-13b-instruct-v2', 'ibm/granite-20b-code-instruct', 'ibm/granite-20b-multilingual', 'ibm/granite-3-2b-instruct', 'ibm/granite-3-8b-instruct', 'ibm/granite-34b-code-instruct', 'ibm/granite-3b-code-instruct', 'ibm/granite-7b-lab', 'ibm/granite-8b-code-instruct', 'ibm/granite-8b-japanese-v2-rc', 'ibm/granite-guardian-3-2b', 'ibm/granite-guardian-3-8b', 'meta-llama/llama-2-13b-chat', 'meta-llama/llama-3-1-70b-instruct', 'meta-llama/llama-3-1-8b-instruct', 'meta-llama/llama-3-2-11b-vision-instruct', 'meta-llama/llama-3-2-1b-instruct', 'meta-llama/llama-3-2-3b-instruct', 'meta-llama/llama-3-2-90b-vision-instruct', 'meta-llama/llama-3-3-70b-instruct', 'meta-llama/llama-3-405b-instruct', 'meta-llama/llama-3-70b-instruct', 'meta-llama/llama-3-8b-instruct', 'meta-llama/llama-guard-3-11b-vision', 'mistralai/mistral-large', 'mistralai/mixtral-8x7b-instruct-v01']\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Model 'ibm/granite-8b-code' is not supported for this environment. Supported models: ['codellama/codellama-34b-instruct-hf', 'google/flan-t5-xl', 'google/flan-t5-xxl', 'google/flan-ul2', 'ibm/granite-13b-chat-v2', 'ibm/granite-13b-instruct-v2', 'ibm/granite-20b-code-instruct', 'ibm/granite-20b-multilingual', 'ibm/granite-3-2b-instruct', 'ibm/granite-3-8b-instruct', 'ibm/granite-34b-code-instruct', 'ibm/granite-3b-code-instruct', 'ibm/granite-7b-lab', 'ibm/granite-8b-code-instruct', 'ibm/granite-8b-japanese-v2-rc', 'ibm/granite-guardian-3-2b', 'ibm/granite-guardian-3-8b', 'meta-llama/llama-2-13b-chat', 'meta-llama/llama-3-1-70b-instruct', 'meta-llama/llama-3-1-8b-instruct', 'meta-llama/llama-3-2-11b-vision-instruct', 'meta-llama/llama-3-2-1b-instruct', 'meta-llama/llama-3-2-3b-instruct', 'meta-llama/llama-3-2-90b-vision-instruct', 'meta-llama/llama-3-3-70b-instruct', 'meta-llama/llama-3-405b-instruct', 'meta-llama/llama-3-70b-instruct', 'meta-llama/llama-3-8b-instruct', 'meta-llama/llama-guard-3-11b-vision', 'mistralai/mistral-large', 'mistralai/mixtral-8x7b-instruct-v01']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_ibm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WatsonxLLM\n\u001b[1;32m      2\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mibm/granite-8b-code\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWatsonxLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapikey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOOyrCi_ATtxuhlJcpEh4-nbkFrKH0R3BreLG1NdvAbba\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://us-south.ml.cloud.ibm.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43macce5b23-91ad-444f-afa0-185f16a0c36f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Additional parameters can be set as needed\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MARC Agent/env/lib/python3.11/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/MARC Agent/env/lib/python3.11/site-packages/langchain_ibm/llms.py:232\u001b[0m, in \u001b[0;36mWatsonxLLM.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m             check_for_attribute(\n\u001b[1;32m    216\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWATSONX_INSTANCE_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m             )\n\u001b[1;32m    219\u001b[0m     credentials \u001b[38;5;241m=\u001b[39m Credentials(\n\u001b[1;32m    220\u001b[0m         url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;241m.\u001b[39mget_secret_value() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m         api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapikey\u001b[38;5;241m.\u001b[39mget_secret_value() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapikey \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify,\n\u001b[1;32m    230\u001b[0m     )\n\u001b[0;32m--> 232\u001b[0m     watsonx_model \u001b[38;5;241m=\u001b[39m \u001b[43mModelInference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwatsonx_model \u001b[38;5;241m=\u001b[39m watsonx_model\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/MARC Agent/env/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/model_inference.py:192\u001b[0m, in \u001b[0;36mModelInference.__init__\u001b[0;34m(self, model_id, deployment_id, params, credentials, project_id, space_id, verify, api_client, validate, persistent_connection)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference: BaseModelInference\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference \u001b[38;5;241m=\u001b[39m \u001b[43mFMModelInference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersistent_connection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersistent_connection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment_id \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment_id)\n",
      "File \u001b[0;32m~/Desktop/MARC Agent/env/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/fm_model_inference.py:85\u001b[0m, in \u001b[0;36mFMModelInference.__init__\u001b[0;34m(self, model_id, api_client, params, validate, persistent_connection)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tech_preview:\n\u001b[0;32m---> 85\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\n\u001b[1;32m     86\u001b[0m             error_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for this environment. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_models\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# check if model is in constricted mode\u001b[39;00m\n\u001b[1;32m     91\u001b[0m _check_model_state(\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id,\n\u001b[1;32m     94\u001b[0m     tech_preview\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tech_preview,\n\u001b[1;32m     95\u001b[0m     model_specs\u001b[38;5;241m=\u001b[39mmodel_specs,\n\u001b[1;32m     96\u001b[0m )\n",
      "\u001b[0;31mWMLClientError\u001b[0m: Model 'ibm/granite-8b-code' is not supported for this environment. Supported models: ['codellama/codellama-34b-instruct-hf', 'google/flan-t5-xl', 'google/flan-t5-xxl', 'google/flan-ul2', 'ibm/granite-13b-chat-v2', 'ibm/granite-13b-instruct-v2', 'ibm/granite-20b-code-instruct', 'ibm/granite-20b-multilingual', 'ibm/granite-3-2b-instruct', 'ibm/granite-3-8b-instruct', 'ibm/granite-34b-code-instruct', 'ibm/granite-3b-code-instruct', 'ibm/granite-7b-lab', 'ibm/granite-8b-code-instruct', 'ibm/granite-8b-japanese-v2-rc', 'ibm/granite-guardian-3-2b', 'ibm/granite-guardian-3-8b', 'meta-llama/llama-2-13b-chat', 'meta-llama/llama-3-1-70b-instruct', 'meta-llama/llama-3-1-8b-instruct', 'meta-llama/llama-3-2-11b-vision-instruct', 'meta-llama/llama-3-2-1b-instruct', 'meta-llama/llama-3-2-3b-instruct', 'meta-llama/llama-3-2-90b-vision-instruct', 'meta-llama/llama-3-3-70b-instruct', 'meta-llama/llama-3-405b-instruct', 'meta-llama/llama-3-70b-instruct', 'meta-llama/llama-3-8b-instruct', 'meta-llama/llama-guard-3-11b-vision', 'mistralai/mistral-large', 'mistralai/mixtral-8x7b-instruct-v01']"
     ]
    }
   ],
   "source": [
    "from langchain_ibm import WatsonxLLM\n",
    "model_id = \"ibm/granite-8b-code\"\n",
    "model = WatsonxLLM(\n",
    "    model_id= model_id,\n",
    "    apikey= \"OOyrCi_ATtxuhlJcpEh4-nbkFrKH0R3BreLG1NdvAbba\",\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\",\n",
    "    project_id= \"acce5b23-91ad-444f-afa0-185f16a0c36f\"\n",
    "    # Additional parameters can be set as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the LLaMA 3 model from Hugging Face\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"meta-llama/Llama-3-8B-Instruct\",\n",
    "    tokenizer=\"meta-llama/Llama-3-8B-Instruct\",\n",
    "    device=0  # Use GPU if available\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
